{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "from surprise import accuracy, Reader, Dataset\n",
        "from surprise import NormalPredictor, KNNBasic, SVD, SVDpp, CoClustering, SlopeOne, NMF, KNNBaseline\n",
        "from surprise.model_selection import cross_validate, KFold, GridSearchCV, train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOQuojqN0QSr"
      },
      "source": [
        "#### **5. Modeling : Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The recommendation will be in three different approach : content-based method, collaborative filtering and combining both in a hybrid model of recommendation system.\n",
        "\n",
        "The difference in recommendations between content-based filtering and collaborative filtering comes from the underlying mechanisms of how these methods work:\n",
        "\n",
        "**A. Content-Based Filtering:**\n",
        "\n",
        "**How it works:** Content-based filtering recommends items that are similar to those a user has liked in the past, based on the features of the items themselves. In this case, features like product_category_name_english are used to find similarities between items.\n",
        "\n",
        "Since the method is based on features (like category, description length, etc.), it will naturally recommend items that are similar to those the user has interacted with in the same category. For example, if the user likes electronics, content-based filtering will recommend other electronics products, as they share similar attributes (e.g., category).\n",
        "\n",
        "**In-Short :** Content-Based Filtering is based solely on the similarity of item features.\n",
        "\n",
        "**B. Collaborative Filtering:**\n",
        "\n",
        "**How it works:** Collaborative filtering uses the preferences of many users to make recommendations. It looks at what other users with similar tastes have liked and recommends those items to you, regardless of the content or category of the items.\n",
        "\n",
        "Collaborative filtering does not directly consider item features like categories. Instead, it looks at patterns of user behavior. If other users who liked the same items as you have also liked items in different categories, it may recommend those cross-category items to you. This is why collaborative filtering can recommend items from different categories—because it leverages user behavior patterns, not just item similarities.\n",
        "\n",
        "**In-Short :** Collaborative Filtering considers user preferences based on their ratings of other items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **5.1 Feature Engineering and Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_olist = pd.read_csv('./dataset/df_olist_clean.csv')\n",
        "\n",
        "df_olist['order_purchase_timestamp'] = pd.to_datetime(df_olist['order_purchase_timestamp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.1.1 Creating New Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate seller average review score\n",
        "df_olist['seller_avg_review_score'] = df_olist.groupby('seller_id')['review_score'].transform('mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.1.2 Dataset Preparation : Model Performance Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will separate the dataset to be used for building and testing models by dividing it between customers who have made their first purchase, which will later be used for a content-based filtering model and a hybrid recommendation system, and customers who have made their second purchase, which will be used for a collaborative filtering model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_order_counts = df_olist.groupby('customer_unique_id')['order_id'].nunique()\n",
        "\n",
        "repeat_customers_ids = customer_order_counts[customer_order_counts > 1].index\n",
        "\n",
        "\n",
        "repeat_buyers = df_olist[df_olist['customer_unique_id'].isin(repeat_customers_ids)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.1.2.A Repeat Buyers Two Transaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Ensure the data contains only customers with exactly 2 transactions\n",
        "repeat_buyers_two_transaction = repeat_buyers.groupby('customer_unique_id').filter(lambda x: len(x) == 2)\n",
        "\n",
        "# 2. Get the last transaction of each unique customer\n",
        "last_transaction = repeat_buyers_two_transaction.sort_values(['customer_unique_id', 'order_id']).groupby('customer_unique_id').tail(1).reset_index(drop=True)\n",
        "\n",
        "# 3. Select the first 100 unique customers' last transactions\n",
        "repeat_buyers_same_category = last_transaction.head(100).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 27)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repeat_buyers_same_category.shape "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.1.2.B Repeat Buyers Different Categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.\n",
        "different_category = repeat_buyers_two_transaction.groupby('customer_unique_id').filter(\n",
        "    lambda x: x.iloc[0]['product_category_name'] != x.iloc[1]['product_category_name']\n",
        ")\n",
        "\n",
        "# 2.\n",
        "different_category_transaction = different_category.groupby('customer_unique_id').tail(1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# 3.\n",
        "repeat_buyers_diff_category = different_category_transaction.head(100).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 27)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repeat_buyers_diff_category.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.1.3 Dataset Preparation : Content-Based Filtering & Hybrid Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(114085, 27)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_olist.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.\n",
        "df_olist = df_olist.merge(repeat_buyers_same_category[['customer_unique_id', 'order_id']], on=['customer_unique_id', 'order_id'], how='left', indicator=True)\n",
        "\n",
        "# 3.\n",
        "df_olist = df_olist[df_olist['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
        "\n",
        "# 4. \n",
        "df_olist = df_olist.merge(repeat_buyers_diff_category[['customer_unique_id', 'order_id']], on=['customer_unique_id', 'order_id'], how='left', indicator=True)\n",
        "\n",
        "\n",
        "# 5.\n",
        "df_olist = df_olist[df_olist['_merge'] == 'left_only'].drop('_merge', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(113889, 27)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. Last check the final dataset row for modeling\n",
        "df_olist.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_content =  df_olist[['product_id','product_category_name']].drop_duplicates()\n",
        "df_hybrid = df_olist.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.1.4 Dataset Preparation : Colaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This step separates customers into repeat buyers (those with more than one purchase) and one-time buyers. This is important for distinguishing between different customer behavior patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WtAGmkEqc9qZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7846, 27)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_collaborative = df_olist[df_olist['customer_unique_id'].isin(repeat_customers_ids)]\n",
        "\n",
        "# 1. Dataset for collaborative filtering\n",
        "df_collaborative = df_collaborative.groupby(['customer_unique_id', 'product_id'])['review_score'].agg('mean').reset_index()\n",
        "\n",
        "df_collaborative = df_collaborative.rename({'review_score':'rating'}, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_collaborative.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **5.2 Content-Based Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.2.1 Similiarity Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(df_content['product_category_name'])\n",
        "\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.2.2 Recommendation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_recommendations(product_id, df_content, cosine_sim, top_n=5):\n",
        "    \n",
        "    idx = df_content[df_content['product_id'] == product_id].index[0]\n",
        "    \n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    \n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    sim_scores = sim_scores[1:top_n+1]  # Skip the item itself\n",
        "\n",
        "    # Extract product IDs and categories\n",
        "    recommended_indices = [i[0] for i in sim_scores]\n",
        "    \n",
        "    recommended_products = df_content.iloc[recommended_indices][['product_id', 'product_category_name']]\n",
        "\n",
        "    return recommended_products\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.2.3. Recommendation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_category_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P23317</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P20373</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>P17672</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>P21112</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>P29007</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    product_id product_category_name\n",
              "2       P23317      office_furniture\n",
              "3       P20373      office_furniture\n",
              "42      P17672      office_furniture\n",
              "72      P21112      office_furniture\n",
              "292     P29007      office_furniture"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "product_id = 'P20845'\n",
        "\n",
        "recommendations = get_recommendations(product_id, df_content, cosine_sim)\n",
        "\n",
        "display(recommendations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.2.4 Content-Based Filtering Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_user_purchased_products(user_id, df_all):\n",
        "    # Filter df_all to get products bought by the specified user\n",
        "    user_purchases = df_all[df_all['customer_unique_id'] == user_id]\n",
        "\n",
        "    # Extract the product IDs of the products purchased by the user\n",
        "    purchased_product_ids = user_purchases['product_id'].unique()\n",
        "\n",
        "    return purchased_product_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['P20845'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_category_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P23317</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P20373</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>P17672</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>P21112</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>P29007</td>\n",
              "      <td>office_furniture</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    product_id product_category_name\n",
              "2       P23317      office_furniture\n",
              "3       P20373      office_furniture\n",
              "42      P17672      office_furniture\n",
              "72      P21112      office_furniture\n",
              "292     P29007      office_furniture"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Content Based Recommendation System Implementation\n",
        "user_id =   'C48272'\n",
        "get_product_id = get_user_purchased_products(user_id,df_olist)\n",
        "product_id_str = get_product_id[0]\n",
        "\n",
        "recommendations = get_recommendations(product_id_str, df_content, cosine_sim, top_n=5)\n",
        "\n",
        "display(get_product_id)\n",
        "display(recommendations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTyNH1SSuhpQ"
      },
      "source": [
        "##### **5.3. Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null = df_collaborative.isnull().sum()\n",
        "null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.3.1 Data Scaling and Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This step scales the ratings and prepares the dataset for training by defining the rating scale and loading it into a dataset object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = (df_collaborative.rating.min(), df_collaborative.rating.max())\n",
        "\n",
        "reader = Reader(rating_scale=scaler)\n",
        "\n",
        "data = Dataset.load_from_df(df_collaborative[['customer_unique_id', 'product_id', 'rating']], reader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.3.2 Data Splitting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This step shuffles the data and splits it into training and test sets, ensuring an unbiased evaluation of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "all_collab = data.raw_ratings\n",
        "random.shuffle(all_collab)\n",
        "\n",
        "# Split data into train and test sets\n",
        "threshold = int(0.8 * len(all_collab))\n",
        "train_raw_collab = all_collab[:threshold]\n",
        "test_raw_collab = all_collab[threshold:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "listed = [all_collab, train_raw_collab, test_raw_collab]\n",
        "names = ['all_collab', 'train_raw_ratings', 'test_raw_ratings']\n",
        "\n",
        "for i, lis in enumerate(listed):\n",
        "    count = len(lis)\n",
        "    print(f\"Shape of {names[i]}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the dataset with train data\n",
        "data.raw_ratings = train_raw_collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.3.3 Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This step defines various recommendation models, performs cross-validation, trains them, and calculates their performance metrics (RMSE) on both training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.3.3.a Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'NormalPredictor': NormalPredictor(),\n",
        "    'SVD': SVD(n_factors=30, n_epochs=25, biased=True, lr_all=0.00004, reg_all=0.4, random_state=47),\n",
        "    'SVDpp': SVDpp(n_factors=50, n_epochs=20, lr_all=0.00008, reg_all=0.4, random_state=47),\n",
        "    'NMF': NMF(n_factors=20, n_epochs=30, lr_bu=0.0000001, lr_bi=0.0000001, reg_pu=5, reg_qi=5, biased=True, random_state=47),\n",
        "    'KNNBasic': KNNBasic(sim_options={'name': 'cosine', 'user_based': False}, random_state=47),\n",
        "    'CoClustering': CoClustering(n_cltr_u=8, n_cltr_i=8, n_epochs=30, random_state=47),\n",
        "    'SlopeOne': SlopeOne()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.3.3.b Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_result = cross_validate(model, data, measures=['RMSE'], cv=5, verbose=False, n_jobs=2)\n",
        "    \n",
        "    # Train model\n",
        "    trainset = data.build_full_trainset()\n",
        "    model.fit(trainset)\n",
        "    \n",
        "    # Calculate RMSE for training set\n",
        "    train_pred = model.test(trainset.build_testset())\n",
        "    train_rmse = accuracy.rmse(train_pred, verbose=False)\n",
        "    \n",
        "    # Calculate RMSE for test set\n",
        "    testset = data.construct_testset(test_raw_collab)\n",
        "    test_pred = model.test(testset)\n",
        "    test_rmse = accuracy.rmse(test_pred, verbose=False)\n",
        "    \n",
        "    results[name] = [train_rmse, test_rmse]\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_comparison = pd.DataFrame(results, index=['RMSE Train', 'RMSE Test']).T\n",
        "print(df_comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.3.4 Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {'n_factors': [25, 50], 'n_epochs': [30, 50], 'lr_all': [0.005, 0.01], 'reg_all': [0.02, 0.1]}\n",
        "gs_svdpp = GridSearchCV(SVDpp, param_grid, measures=['rmse'], cv=5)\n",
        "gs_svdpp.fit(data)\n",
        "\n",
        "best_score_svdpp = gs_svdpp.best_score['rmse']\n",
        "best_param_svdpp = gs_svdpp.best_params['rmse']\n",
        "\n",
        "print(f'Best score: {best_score_svdpp}')\n",
        "print(f'Best parameter: {best_param_svdpp}')\n",
        "\n",
        "# Create and fit the best model\n",
        "best_model_svdpp = SVDpp(**best_param_svdpp)\n",
        "\n",
        "best_model_svdpp.fit(data.build_full_trainset())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYQ4ndcpNwkl"
      },
      "source": [
        "##### **5.4 Hybrid Recommendation System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_content.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_collaborative.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reader = Reader(rating_scale=(1, 5))  # Adjust rating scale if needed\n",
        "data = Dataset.load_from_df(df_collaborative[['customer_unique_id', 'product_id', 'rating']], reader)\n",
        "\n",
        "trainset = data.build_full_trainset()\n",
        "svdpp = SVDpp()\n",
        "svdpp.fit(trainset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svdpp_model = best_model_svdpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hybrid_recommendation_system(user_id, df_hybrid, df_content, cosine_sim, svdpp_model, top_n=5):\n",
        "    # Step 1: Content-Based Recommendation\n",
        "    get_product_id = get_user_purchased_products(user_id, df_hybrid)\n",
        "    content_based_recommendations = []\n",
        "\n",
        "    if get_product_id:  # Ensure user has purchased products\n",
        "        product_id_str = get_product_id[0]  # Get the first product ID from the list\n",
        "        content_based_recommendations = get_recommendations(product_id_str, df_content, cosine_sim, top_n=top_n)\n",
        "\n",
        "    # Step 2: Collaborative Filtering - Get top 2 recommended categories\n",
        "    user_rated_items = df_hybrid[df_hybrid['customer_unique_id'] == user_id]['product_id'].values\n",
        "\n",
        "    category_predictions = []\n",
        "    for product_id in df_content['product_id'].unique():\n",
        "        if product_id not in user_rated_items:\n",
        "            pred = svdpp_model.predict(user_id, product_id)\n",
        "            category = df_content[df_content['product_id'] == product_id]['product_category_name'].values[0]\n",
        "            category_predictions.append((category, pred.est))\n",
        "\n",
        "    # Sort and select top 2 categories based on the prediction score\n",
        "    top_categories = sorted(category_predictions, key=lambda x: x[1], reverse=True)[:2]\n",
        "    top_categories = [category for category, _ in top_categories]\n",
        "\n",
        "    # Step 3: Cascade into Content-Based for top 2 categories\n",
        "    cascade_recommendations = []\n",
        "    for category in top_categories:\n",
        "        # Filter products by category\n",
        "        category_products = df_content[df_content['product_category_name'] == category]['product_id'].values\n",
        "        for product_id in category_products[:2]:  # Select 2 products for each category\n",
        "            recs = get_recommendations(product_id, df_content, cosine_sim, top_n=top_n)\n",
        "            cascade_recommendations.extend(recs[['product_id', 'product_category_name']].values.tolist())\n",
        "\n",
        "    return {\n",
        "        \"content_based_recommendations\": content_based_recommendations,\n",
        "        \"collaborative_filtering_recommendations\": cascade_recommendations\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_id = '861eff4711a542e4b93843c6dd7febb0'\n",
        "\n",
        "# Call the hybrid recommendation system function\n",
        "recommendations = hybrid_recommendation_system(user_id, df_hybrid, df_content, cosine_sim, svdpp_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_recommendations(recommendations):\n",
        "    # Print Content-Based Recommendations\n",
        "    print(\"Similar Items:\\n\")\n",
        "    for index, row in recommendations[\"content_based_recommendations\"].iterrows():\n",
        "        print(f\"Product ID: {row['product_id']}, Category: {row['product_category_name']}\")\n",
        "\n",
        "    print(\"\\nYou might also like:\\n\")\n",
        "    for rec in recommendations[\"collaborative_filtering_recommendations\"]:\n",
        "        print(f\"Product ID: {rec[0]}, Category: {rec[1]}\")\n",
        "\n",
        "# Call the function to print recommendations\n",
        "print_recommendations(recommendations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **5.5 Recommendation System For New User**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a cold-start scenario, where a new user has just joined the platform and there is no prior interaction data, our recommendation system will focus on suggesting popular items. These items are selected based on metrics such as the most purchased, most reviewed, and those trending in the user's geographic area. This approach ensures that new users receive relevant and appealing recommendations even without a personalized history.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.5.1 Popularity-Based Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the initial stages, the recommendation system leverages a popularity-based approach to provide immediate suggestions. This method selects items based on various popularity metrics:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.5.1.a Most Purchased Items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Items with the highest purchase frequency across the platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_popular_items(data, n_recs):\n",
        "    top_n_items = data.product_id.value_counts().sort_values(ascending=False)[:n_recs].index\n",
        "    return list(top_n_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.5.1.b Popular Items in User's Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Items that are trending within the user's geographic location, which can help provide contextually relevant suggestions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def popular_in_your_area(data, state, n_recs):\n",
        "    location_df = data[data.customer_state == state]\n",
        "    top_n_items = location_df.product_id.value_counts().sort_values(ascending=False)[:n_recs].index\n",
        "    return list(top_n_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.5.2 Implementation of Recomendation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def first_time_recommender(data, uid, n_recs):\n",
        "    hot_items = find_popular_items(data, n_recs)\n",
        "    state = data[data.customer_unique_id==uid].customer_state.max()\n",
        "    popular_in_area = popular_in_your_area(data, state, n_recs)\n",
        "\n",
        "    print(f\"Hot items you might like:\\n {hot_items}\\n\")\n",
        "    print(f\"Popular items in your area:\\n {popular_in_area}\")\n",
        "\n",
        "    recommendation = {'Hot Items': hot_items, 'Area': popular_in_area}\n",
        "\n",
        "    return recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hot items you might like:\n",
            " ['P21247', 'P18956']\n",
            "\n",
            "Popular items in your area:\n",
            " ['P21247', 'P18956']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Hot Items': ['P21247', 'P18956'], 'Area': ['P21247', 'P18956']}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example Recommendation\n",
        "recommendation = first_time_recommender(df_hybrid, 'C48272', 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **5.6 Batch Processing For Unseen Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batch processing allows us to efficiently generate recommendations for a large set of users. Here, we perform batch processing for unseen data after applying collaborative filtering. The following steps outline the process in a structured way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.1 Second Transaction with same Categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.1.1 Generate Predictions for Each User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Extract Unique User IDs\n",
        "user_ids = repeat_buyers_same_category['customer_unique_id'].unique()\n",
        "\n",
        "# 2.  Initialize Storage for Recommendations\n",
        "top_3_recommendations = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for user_id in user_ids:\n",
        "    \n",
        "    predictions_list = []\n",
        "    items = repeat_buyers_same_category['product_id'].unique()\n",
        "\n",
        "    for item_id in items:\n",
        "        prediction = svdpp.predict(user_id, item_id)\n",
        "        product_category = repeat_buyers_same_category[\n",
        "            repeat_buyers_same_category['product_id'] == item_id]['product_category_name'].values[0]\n",
        "        predictions_list.append({\n",
        "            'user_id': user_id,\n",
        "            'item_id': item_id,\n",
        "            'product_category': product_category,\n",
        "            'estimated_rating': prediction.est\n",
        "        })\n",
        "        \n",
        "    df_user_predictions = pd.DataFrame(predictions_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.1.2  Calculate Average Estimated Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_avg_ratings = df_user_predictions.groupby('product_category')['estimated_rating'].mean().reset_index()\n",
        "\n",
        "df_top_2 = df_avg_ratings.sort_values(by='estimated_rating', ascending=False).head(2)\n",
        "\n",
        "own_category = repeat_buyers_same_category[\n",
        "    repeat_buyers_same_category['customer_unique_id'] == user_id].iloc[-1]['product_category_name']\n",
        "top_3_categories = [own_category] + df_top_2['product_category'].tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.1.3 Merge Recommendations with Transaction Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_top_3_recommendations = pd.DataFrame(top_3_recommendations)\n",
        "\n",
        "merged_df = pd.merge(repeat_buyers_same_category, df_top_3_recommendations, left_on='customer_unique_id', right_on='user_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.1.4 Check Recommendation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df['is_in_top_3'] = merged_df.apply(\n",
        "    lambda row: row['product_category_name'] in row['top_3_categories'], axis=1\n",
        ")\n",
        "percentage_existing_prediction = merged_df['is_in_top_3'].mean() * 100\n",
        "print(f\"Percentage in top 3 recommendations: {percentage_existing_prediction:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.1.5 Compare Product Categories Between Transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "repeat_buyers_same_category = repeat_buyers_same_category.sort_values(by=['customer_unique_id', 'order_id'])\n",
        "df_comparison = repeat_buyers_same_category.groupby('customer_unique_id').apply(\n",
        "    lambda x: x.iloc[0]['product_category_name'] == x.iloc[1]['product_category_name']\n",
        ").reset_index()\n",
        "df_comparison.columns = ['customer_unique_id', 'same_category']\n",
        "percentage_same_category = df_comparison['same_category'].mean() * 100\n",
        "print(f\"Percentage with the same category for both transactions: {percentage_same_category:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.2 Second Transcation with Different Categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.2.1 Generate Predictions for Each User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Extract Unique User IDs\n",
        "user_ids = repeat_buyers_diff_category['customer_unique_id'].unique()\n",
        "\n",
        "# 2.  Initialize Storage for Recommendations\n",
        "top_3_recommendations2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for user_id in user_ids:\n",
        "    predictions_list = []\n",
        "\n",
        "    # Get the list of all items (products) in the dataset\n",
        "    items = repeat_buyers_diff_category['product_id'].unique()\n",
        "\n",
        "    # Predict the rating for each item for the current user\n",
        "    for item_id in items:\n",
        "        prediction = svdpp.predict(user_id, item_id)\n",
        "        product_category = repeat_buyers_diff_category[\n",
        "            repeat_buyers_diff_category['product_id'] == item_id]['product_category_name'].values[0]\n",
        "\n",
        "        # Append the prediction details to the list\n",
        "        predictions_list.append({\n",
        "            'user_id': user_id,\n",
        "            'item_id': item_id,\n",
        "            'product_category': product_category,\n",
        "            'estimated_rating': prediction.est\n",
        "        })\n",
        "\n",
        "    # Convert the predictions list to a DataFrame\n",
        "    df_user_predictions2 = pd.DataFrame(predictions_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.2.2  Calculate Average Estimated Ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_avg_ratings2 = df_user_predictions2.groupby('product_category')['estimated_rating'].mean().reset_index()\n",
        "\n",
        "df_top2 = df_avg_ratings2.sort_values(by='estimated_rating', ascending=False).head(2)\n",
        "\n",
        "own_category2 = repeat_buyers_diff_category[\n",
        "    repeat_buyers_diff_category['customer_unique_id'] == user_id].iloc[-1]['product_category_name']\n",
        "top_3_categories2 = [own_category2] + df_top2['product_category'].tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.2.3 Merge Recommendations with Transaction Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_3_recommendations2.append({\n",
        "    'user_id': user_id,\n",
        "    'top_3_categories': top_3_categories2\n",
        "})\n",
        "\n",
        "df_top_3_recommendations2 = pd.DataFrame(top_3_recommendations2)\n",
        "\n",
        "\n",
        "merged_df2 = pd.merge(repeat_buyers_diff_category, df_top_3_recommendations2, left_on='customer_unique_id', right_on='user_id')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    5.6.2.4 Check Recommendation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df2['is_in_top_3'] = merged_df2.apply(\n",
        "    lambda row: row['product_category_name'] in row['top_3_categories'], axis=1\n",
        ")\n",
        "\n",
        "percentage_existing_prediction2 = merged_df2['is_in_top_3'].mean() * 100\n",
        "print(f\"The percentage of product categories in the dataset that are in the top 3 recommendations is: {percentage_existing_prediction2:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **6. Conclusion And Recommendation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **6.1 Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "#####**6.1. Conclusion** \n",
        "\n",
        "1. analysis Result of factors causing the low customer retention rate based on customer behavior as follows :\n",
        "\n",
        "1.1. The top three product preferences for repeat buyers are bed_bath_table, furniture, and sport_leisure, while the top three for one-time buyers are bed_bath_table, health_beauty, and sports_leisure. There is a noticeable difference where one-time buyers focus more on beauty and health-related items, which could be a good opportunity for personalized offers.\n",
        "\n",
        "1.2. The largest purchase distribution for both one-time buyers and repeat buyers is concentrated in three cities: Sao Paulo, Rio de Janeiro, and Belo Horizonte. The top three regions are SP (Sao Paulo), RJ (Rio de Janeiro), and MG (Minas Gerais). Analysis shows that these cities and regions also have the highest customer and seller distribution and are among the three largest cities in Brazil, making them a potential focus for business growth through targeted promotional strategies.\n",
        "\n",
        "1.3. Customer satisfaction analysis for both one-time and repeat buyers shows good scores, with satisfaction levels of 4 & 5 above 70%. However, the analysis also reveals high dissatisfaction scores of 1 & 2, exceeding 10% for both groups. One of the factors affecting these scores is the timeliness of the shipping process, which contributes to the 1 & 2 satisfaction scores but only accounts for about 30%. The remaining analysis from customer comments indicates that over 70% of customer dissatisfaction is due to issues such as incorrect deliveries, damaged goods, undelivered items, and errors in shipment quantity. This is a key area that needs improvement to enhance customer satisfaction, increase customer retention, and positively impact future business growth.\n",
        "\n",
        "1.4. There is no significant difference in the choice of payment methods and payment installments between one-time buyers and repeat buyers. However, the analysis of purchase frequency by day shows that one-time buyers tend to make more purchases on Mondays, while repeat buyers tend to buy more on Tuesdays. Additionally, based on time, one-time buyers make most of their purchases between 10 AM and 4 PM, while repeat customers peak at 9 AM and 2 PM. Implementing business strategies based on these findings can help Olist improve the effectiveness of marketing campaigns and personalize the shopping experience.\n",
        "\n",
        "1.5. Regarding the contribution to the company’s revenue, one-time buyers, who make up 97% of the total customer base, contribute 94% of the revenue, while repeat customers, who only make up 3% of the customer base, contribute nearly twice as much, with 5.5% of the revenue.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **6.2 Recommendation**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KLCK3e4-QJ8P",
        "kb041fmICjPn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
